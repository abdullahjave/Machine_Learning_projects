{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 1 (Random Forest): 0.8733333333333333\n",
      "Accuracy of Model 2 (Gradient Boosting): 0.8533333333333334\n",
      "Accuracy of Model 3 (Logistic Regression): 0.8\n",
      "Ensemble Accuracy (Max Voting): 0.8866666666666667\n",
      "Ensemble Accuracy (Averaging): 0.8733333333333333\n",
      "Ensemble Accuracy (Weighted Averaging): 0.8733333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Generate synthetic dataset \n",
    "X, y = make_classification( \n",
    "    n_samples=500,  \n",
    "    n_features=10,  \n",
    "    n_informative=8,  \n",
    "    n_redundant=2,  \n",
    "    n_classes=2,  \n",
    "    random_state=42 \n",
    ") \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "# Base models \n",
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42) \n",
    "model2 = GradientBoostingClassifier(n_estimators=100, random_state=42) \n",
    "model3 = LogisticRegression(random_state=42) \n",
    "\n",
    "# Train models \n",
    "model1.fit(X_train, y_train) \n",
    "model2.fit(X_train, y_train) \n",
    "model3.fit(X_train, y_train) \n",
    "\n",
    "# Predictions \n",
    "pred1 = model1.predict(X_test) \n",
    "pred2 = model2.predict(X_test) \n",
    "pred3 = model3.predict(X_test) \n",
    "\n",
    "# Combine predictions using max voting \n",
    "def max_voting(preds): \n",
    "    preds_array = np.array(preds).T \n",
    "    final_preds = [np.bincount(row).argmax() for row in preds_array] \n",
    "    return np.array(final_preds) \n",
    "\n",
    "# Combine predictions using averaging \n",
    "def averaging(pred_probs): \n",
    "    avg_probs = np.mean(pred_probs, axis=0) \n",
    "    return np.argmax(avg_probs, axis=1) \n",
    "\n",
    "# Combine predictions using weighted averaging \n",
    "def weighted_averaging(pred_probs, weights): \n",
    "    weighted_avg_probs = np.average(pred_probs, axis=0, weights=weights) \n",
    "    return np.argmax(weighted_avg_probs, axis=1) \n",
    "\n",
    "# Max Voting \n",
    "final_pred_voting = max_voting([pred1, pred2, pred3]) \n",
    "voting_acc = accuracy_score(y_test, final_pred_voting) \n",
    "\n",
    "# Averaging \n",
    "probs1 = model1.predict_proba(X_test) \n",
    "probs2 = model2.predict_proba(X_test) \n",
    "probs3 = model3.predict_proba(X_test) \n",
    "final_pred_avg = averaging([probs1, probs2, probs3]) \n",
    "avg_acc = accuracy_score(y_test, final_pred_avg) \n",
    "\n",
    "# Weighted Averaging \n",
    "weights = [0.5, 0.3, 0.2]  # Example weights for models \n",
    "final_pred_weighted_avg = weighted_averaging([probs1, probs2, probs3], weights) \n",
    "weighted_avg_acc = accuracy_score(y_test, final_pred_weighted_avg) \n",
    "\n",
    "# Print results \n",
    "print(\"Accuracy of Model 1 (Random Forest):\", accuracy_score(y_test, pred1)) \n",
    "print(\"Accuracy of Model 2 (Gradient Boosting):\", accuracy_score(y_test, pred2)) \n",
    "print(\"Accuracy of Model 3 (Logistic Regression):\", accuracy_score(y_test, pred3)) \n",
    "print(\"Ensemble Accuracy (Max Voting):\", voting_acc) \n",
    "print(\"Ensemble Accuracy (Averaging):\", avg_acc) \n",
    "print(\"Ensemble Accuracy (Weighted Averaging):\", weighted_avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 1 (Random Forest): 0.8866666666666667\n",
      "Accuracy of Model 2 (Gradient Boosting): 0.8866666666666667\n",
      "Accuracy of Model 3 (Logistic Regression): 0.82\n",
      "Ensemble Accuracy (Max Voting): 0.8866666666666667\n",
      "Ensemble Accuracy (Averaging): 0.88\n",
      "Ensemble Accuracy (Weighted Averaging): 0.8866666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Modified dataset creation\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,         \n",
    "    n_features=20,          \n",
    "    n_informative=15,       \n",
    "    n_redundant=5,          \n",
    "    n_classes=2,            \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train models again\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "\n",
    "# Max Voting\n",
    "final_pred_voting = max_voting([pred1, pred2, pred3])\n",
    "voting_acc = accuracy_score(y_test, final_pred_voting)\n",
    "\n",
    "# Averaging\n",
    "probs1 = model1.predict_proba(X_test)\n",
    "probs2 = model2.predict_proba(X_test)\n",
    "probs3 = model3.predict_proba(X_test)\n",
    "final_pred_avg = averaging([probs1, probs2, probs3])\n",
    "avg_acc = accuracy_score(y_test, final_pred_avg)\n",
    "\n",
    "# Weighted Averaging\n",
    "final_pred_weighted_avg = weighted_averaging([probs1, probs2, probs3], weights)\n",
    "weighted_avg_acc = accuracy_score(y_test, final_pred_weighted_avg)\n",
    "\n",
    "# Print updated results\n",
    "print(\"Accuracy of Model 1 (Random Forest):\", accuracy_score(y_test, pred1))\n",
    "print(\"Accuracy of Model 2 (Gradient Boosting):\", accuracy_score(y_test, pred2))\n",
    "print(\"Accuracy of Model 3 (Logistic Regression):\", accuracy_score(y_test, pred3))\n",
    "print(\"Ensemble Accuracy (Max Voting):\", voting_acc)\n",
    "print(\"Ensemble Accuracy (Averaging):\", avg_acc)\n",
    "print(\"Ensemble Accuracy (Weighted Averaging):\", weighted_avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 1 (Random Forest): 0.8866666666666667\n",
      "Accuracy of Model 2 (Gradient Boosting): 0.8866666666666667\n",
      "Accuracy of Model 3 (Logistic Regression): 0.82\n",
      "Accuracy of Model 4 (SVM): 0.93\n",
      "Ensemble Accuracy (Max Voting): 0.8966666666666666\n",
      "Ensemble Accuracy (Averaging): 0.9066666666666666\n",
      "Ensemble Accuracy (Weighted Averaging): 0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "# Create a synthetic dataset with modified parameters\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,       \n",
    "    n_features=20,        \n",
    "    n_informative=15,     \n",
    "    n_redundant=5,        \n",
    "    n_classes=2,          \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2 = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "model4 = SVC(random_state=42, probability=True)  # Support Vector Machine\n",
    "\n",
    "# Train all models\n",
    "model1.fit(X_train, y_train)  # Random Forest\n",
    "model2.fit(X_train, y_train)  # Gradient Boosting\n",
    "model3.fit(X_train, y_train)  # Logistic Regression\n",
    "model4.fit(X_train, y_train)  # SVM\n",
    "\n",
    "# Predictions for all models\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "\n",
    "# Predictions probabilities for averaging/weighted averaging\n",
    "probs1 = model1.predict_proba(X_test)\n",
    "probs2 = model2.predict_proba(X_test)\n",
    "probs3 = model3.predict_proba(X_test)\n",
    "probs4 = model4.predict_proba(X_test)\n",
    "\n",
    "# Max Voting\n",
    "final_pred_voting = max_voting([pred1, pred2, pred3, pred4])\n",
    "voting_acc = accuracy_score(y_test, final_pred_voting)\n",
    "\n",
    "# Averaging\n",
    "final_pred_avg = averaging([probs1, probs2, probs3, probs4])\n",
    "avg_acc = accuracy_score(y_test, final_pred_avg)\n",
    "\n",
    "# Weighted Averaging\n",
    "weights = [0.5, 0.3, 0.2, 0.1]  # Example weights for models, adjust if needed\n",
    "final_pred_weighted_avg = weighted_averaging([probs1, probs2, probs3, probs4], weights)\n",
    "weighted_avg_acc = accuracy_score(y_test, final_pred_weighted_avg)\n",
    "\n",
    "# Print updated results\n",
    "print(\"Accuracy of Model 1 (Random Forest):\", accuracy_score(y_test, pred1))\n",
    "print(\"Accuracy of Model 2 (Gradient Boosting):\", accuracy_score(y_test, pred2))\n",
    "print(\"Accuracy of Model 3 (Logistic Regression):\", accuracy_score(y_test, pred3))\n",
    "print(\"Accuracy of Model 4 (SVM):\", accuracy_score(y_test, pred4))\n",
    "print(\"Ensemble Accuracy (Max Voting):\", voting_acc)\n",
    "print(\"Ensemble Accuracy (Averaging):\", avg_acc)\n",
    "print(\"Ensemble Accuracy (Weighted Averaging):\", weighted_avg_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Averaging Accuracy (Weights [0.2, 0.2, 0.2, 0.2]): 0.9067\n",
      "Weighted Averaging Accuracy (Weights [0.4, 0.3, 0.2, 0.1]): 0.9000\n",
      "Weighted Averaging Accuracy (Weights [0.1, 0.1, 0.4, 0.4]): 0.9267\n",
      "Weighted Averaging Accuracy (Weights [0.3, 0.3, 0.2, 0.2]): 0.9033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Base models\n",
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2 = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "model4 = SVC(probability=True, random_state=42)  # Enable probability estimates for averaging\n",
    "\n",
    "# Train models\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predictions probabilities (for averaging and weighted averaging)\n",
    "probs1 = model1.predict_proba(X_test)\n",
    "probs2 = model2.predict_proba(X_test)\n",
    "probs3 = model3.predict_proba(X_test)\n",
    "probs4 = model4.predict_proba(X_test)\n",
    "\n",
    "# Function for weighted averaging\n",
    "def weighted_averaging(pred_probs, weights):\n",
    "    weighted_avg_probs = np.average(pred_probs, axis=0, weights=weights)\n",
    "    return np.argmax(weighted_avg_probs, axis=1)\n",
    "\n",
    "\n",
    "weight_sets = [\n",
    "    [0.2, 0.2, 0.2, 0.2],  \n",
    "    [0.4, 0.3, 0.2, 0.1],     \n",
    "    [0.1, 0.1, 0.4, 0.4],     \n",
    "    [0.3, 0.3, 0.2, 0.2]      \n",
    "]\n",
    "\n",
    "# Evaluate weighted averaging for each weight set\n",
    "for i, weights in enumerate(weight_sets):\n",
    "    final_pred_weighted_avg = weighted_averaging([probs1, probs2, probs3, probs4], weights)\n",
    "    weighted_avg_acc = accuracy_score(y_test, final_pred_weighted_avg)\n",
    "    print(f\"Weighted Averaging Accuracy (Weights {weights}): {weighted_avg_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Averaging Accuracy (Weights [0.2, 0.2, 0.2, 0.2]): 0.9067\n",
      "Weighted Averaging Accuracy (Weights [0.4, 0.3, 0.2, 0.1]): 0.9000\n",
      "Weighted Averaging Accuracy (Weights [0.1, 0.1, 0.4, 0.4]): 0.9267\n",
      "Weighted Averaging Accuracy (Weights [0.3, 0.3, 0.2, 0.2]): 0.9033\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Base models\n",
    "model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model2 = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "model4 = SVC(probability=True, random_state=42)  # Enable probability estimates for averaging\n",
    "\n",
    "# Train models\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "# Predictions probabilities (for averaging and weighted averaging)\n",
    "probs1 = model1.predict_proba(X_test)\n",
    "probs2 = model2.predict_proba(X_test)\n",
    "probs3 = model3.predict_proba(X_test)\n",
    "probs4 = model4.predict_proba(X_test)\n",
    "\n",
    "# Function for weighted averaging\n",
    "def weighted_averaging(pred_probs, weights):\n",
    "    weighted_avg_probs = np.average(pred_probs, axis=0, weights=weights)\n",
    "    return np.argmax(weighted_avg_probs, axis=1)\n",
    "\n",
    "weights1 = [0.2, 0.2, 0.2, 0.2]\n",
    "final_pred_weighted_avg1 = weighted_averaging([probs1, probs2, probs3, probs4], weights1)\n",
    "weighted_avg_acc1 = accuracy_score(y_test, final_pred_weighted_avg1)\n",
    "print(f\"Weighted Averaging Accuracy (Weights {weights1}): {weighted_avg_acc1:.4f}\")\n",
    "\n",
    "weights2 = [0.4, 0.3, 0.2, 0.1]\n",
    "final_pred_weighted_avg2 = weighted_averaging([probs1, probs2, probs3, probs4], weights2)\n",
    "weighted_avg_acc2 = accuracy_score(y_test, final_pred_weighted_avg2)\n",
    "print(f\"Weighted Averaging Accuracy (Weights {weights2}): {weighted_avg_acc2:.4f}\")\n",
    "\n",
    "weights3 = [0.1, 0.1, 0.4, 0.4]\n",
    "final_pred_weighted_avg3 = weighted_averaging([probs1, probs2, probs3, probs4], weights3)\n",
    "weighted_avg_acc3 = accuracy_score(y_test, final_pred_weighted_avg3)\n",
    "print(f\"Weighted Averaging Accuracy (Weights {weights3}): {weighted_avg_acc3:.4f}\")\n",
    "\n",
    "weights4 = [0.3, 0.3, 0.2, 0.2]\n",
    "final_pred_weighted_avg4 = weighted_averaging([probs1, probs2, probs3, probs4], weights4)\n",
    "weighted_avg_acc4 = accuracy_score(y_test, final_pred_weighted_avg4)\n",
    "print(f\"Weighted Averaging Accuracy (Weights {weights4}): {weighted_avg_acc4:.4f}\")\n",
    "\n",
    "# Models' individual predictions (not used here, commented for clarity)\n",
    "# pred1 = model1.predict(X_test)\n",
    "# pred2 = model2.predict(X_test)\n",
    "# pred3 = model3.predict(X_test)\n",
    "# pred4 = model4.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 1 (Random Forest): 0.8866666666666667\n",
      "Accuracy of Model 2 (Gradient Boosting): 0.8866666666666667\n",
      "Accuracy of Model 3 (Logistic Regression): 0.82\n",
      "Accuracy of Model 4 (SVM): 0.93\n",
      "\n",
      "Ensemble Accuracy (Max Voting): 0.8966666666666666\n",
      "Ensemble Accuracy (Weighted Averaging - Equal Weights): 0.9066666666666666\n",
      "Ensemble Accuracy (Weighted Averaging - RF Focus): 0.9\n",
      "Ensemble Accuracy (Weighted Averaging - LR & SVM Focus): 0.9266666666666666\n",
      "Ensemble Accuracy (Weighted Averaging - RF & GB Focus): 0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Individual model predictions\n",
    "pred1 = model1.predict(X_test)  # Random Forest\n",
    "pred2 = model2.predict(X_test)  # Gradient Boosting\n",
    "pred3 = model3.predict(X_test)  # Logistic Regression\n",
    "pred4 = model4.predict(X_test)  # SVM\n",
    "\n",
    "# Individual model accuracies\n",
    "acc1 = accuracy_score(y_test, pred1)  # Random Forest accuracy\n",
    "acc2 = accuracy_score(y_test, pred2)  # Gradient Boosting accuracy\n",
    "acc3 = accuracy_score(y_test, pred3)  # Logistic Regression accuracy\n",
    "acc4 = accuracy_score(y_test, pred4)  # SVM accuracy\n",
    "\n",
    "# Ensemble methods' accuracies\n",
    "final_pred_voting = max_voting([pred1, pred2, pred3, pred4])\n",
    "voting_acc = accuracy_score(y_test, final_pred_voting)\n",
    "\n",
    "# Using previous weighted averaging results\n",
    "# Weighted Averaging Results\n",
    "weighted_avg_acc1 = accuracy_score(y_test, weighted_averaging([probs1, probs2, probs3, probs4], [0.25, 0.25, 0.25, 0.25]))\n",
    "weighted_avg_acc2 = accuracy_score(y_test, weighted_averaging([probs1, probs2, probs3, probs4], [0.4, 0.3, 0.2, 0.1]))\n",
    "weighted_avg_acc3 = accuracy_score(y_test, weighted_averaging([probs1, probs2, probs3, probs4], [0.1, 0.1, 0.4, 0.4]))\n",
    "weighted_avg_acc4 = accuracy_score(y_test, weighted_averaging([probs1, probs2, probs3, probs4], [0.3, 0.3, 0.2, 0.2]))\n",
    "\n",
    "# Print all results\n",
    "print(\"Accuracy of Model 1 (Random Forest):\", acc1)\n",
    "print(\"Accuracy of Model 2 (Gradient Boosting):\", acc2)\n",
    "print(\"Accuracy of Model 3 (Logistic Regression):\", acc3)\n",
    "print(\"Accuracy of Model 4 (SVM):\", acc4)\n",
    "\n",
    "print(\"\\nEnsemble Accuracy (Max Voting):\", voting_acc)\n",
    "print(\"Ensemble Accuracy (Weighted Averaging - Equal Weights):\", weighted_avg_acc1)\n",
    "print(\"Ensemble Accuracy (Weighted Averaging - RF Focus):\", weighted_avg_acc2)\n",
    "print(\"Ensemble Accuracy (Weighted Averaging - LR & SVM Focus):\", weighted_avg_acc3)\n",
    "print(\"Ensemble Accuracy (Weighted Averaging - RF & GB Focus):\", weighted_avg_acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
